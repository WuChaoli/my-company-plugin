#!/usr/bin/env python3
"""
Symbol index builder for architecture generator (Phase 2).

Builds SQLite index of code symbols (classes, functions, variables).
Supports Python (AST) and JavaScript/TypeScript (regex).

Phase 2 Features:
- Serena MCP integration (fallback to SQLite)
- Enhanced symbol extraction
"""

import ast
import json
import os
import re
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Set

from utils import (
    parse_gitignore,
    should_include_file,
    get_relative_path,
    normalize_path,
    detect_file_type,
)

# Try to import enhanced AST analyzer
try:
    import sys
    # Add scripts directory to path
    scripts_dir = Path(__file__).parent
    if str(scripts_dir) not in sys.path:
        sys.path.insert(0, str(scripts_dir))

    from enhanced_ast_analyzer import EnhancedASTAnalyzer
    ENHANCED_AST_AVAILABLE = True
except ImportError:
    ENHANCED_AST_AVAILABLE = False


class SymbolIndexBuilder:
    """ç¬¦å·ç´¢å¼•æ„å»ºå™¨ï¼ˆPhase 2ï¼šæ”¯æŒ Serena é›†æˆï¼‰"""

    def __init__(
        self,
        root_path: Path,
        db_path: str = "symbols.db",
        gitignore_path: Path = None,
    ):
        """
        åˆå§‹åŒ–ç¬¦å·ç´¢å¼•æ„å»ºå™¨

        Args:
            root_path: é¡¹ç›®æ ¹ç›®å½•
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            gitignore_path: .gitignore æ–‡ä»¶è·¯å¾„

        æ³¨æ„ï¼š
            - å½“å‰ç‰ˆæœ¬ä½¿ç”¨ SQLite ä½œä¸ºç¬¦å·ç´¢å¼•åç«¯
            - Serena MCP é›†æˆæ­£åœ¨å¼€å‘ä¸­
            - å¦‚éœ€ä½¿ç”¨ Serenaï¼Œè¯·åœ¨ Claude Code ä¸­é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨
        """
        self.root_path = normalize_path(root_path)
        self.db_path = db_path
        self.exclude_patterns = parse_gitignore(gitignore_path)
        self.conn: Optional[sqlite3.Connection] = None

        print("   ğŸ’¾ Using SQLite for symbol indexing")
        print("   ğŸ’¡ æç¤ºï¼šåœ¨ Claude Code ä¸­å¯ä½¿ç”¨ Serena MCP è¿›è¡Œç¬¦å·çº§åˆ†æ")

    def build_index(self) -> Optional[str]:
        """
        æ„å»ºç¬¦å·ç´¢å¼•

        Returns:
            æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()

        # æ”¶é›†æ‰€æœ‰æºä»£ç æ–‡ä»¶
        source_files = self._collect_source_files()

        # ç´¢å¼•æ¯ä¸ªæ–‡ä»¶
        for file_path in source_files:
            self._index_file(file_path)

        # å…³é—­æ•°æ®åº“è¿æ¥
        self.conn.close()

        return self.db_path

    def _init_database(self):
        """åˆå§‹åŒ– SQLite æ•°æ®åº“"""
        self.conn = sqlite3.connect(self.db_path)
        cursor = self.conn.cursor()

        # åˆ›å»ºç¬¦å·è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS symbols (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                kind TEXT NOT NULL,
                file_path TEXT NOT NULL,
                line_number INTEGER,
                end_line_number INTEGER,
                parent_id INTEGER,
                metadata TEXT,
                UNIQUE(name, kind, file_path, line_number)
            )
        """)

        # åˆ›å»ºä¾èµ–å…³ç³»è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS dependencies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                from_symbol INTEGER NOT NULL,
                to_symbol INTEGER NOT NULL,
                dep_type TEXT NOT NULL,
                FOREIGN KEY (from_symbol) REFERENCES symbols(id),
                FOREIGN KEY (to_symbol) REFERENCES symbols(id)
            )
        """)

        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbols_name ON symbols(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbols_kind ON symbols(kind)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbols_file ON symbols(file_path)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_deps_from ON dependencies(from_symbol)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_deps_to ON dependencies(to_symbol)")

        self.conn.commit()

    def _collect_source_files(self) -> List[Path]:
        """æ”¶é›†æ‰€æœ‰æºä»£ç æ–‡ä»¶"""
        source_files = []

        for file_path in self.root_path.rglob('*'):
            if not file_path.is_file():
                continue

            if not should_include_file(file_path, self.exclude_patterns, self.root_path):
                continue

            file_type = detect_file_type(file_path)
            if file_type in ['python', 'javascript', 'typescript']:
                source_files.append(file_path)

        return source_files

    def _index_file(self, file_path: Path):
        """ç´¢å¼•å•ä¸ªæ–‡ä»¶"""
        file_type = detect_file_type(file_path)
        rel_path = str(get_relative_path(file_path, self.root_path))

        if file_type == 'python':
            self._index_python_file(file_path, rel_path)
        elif file_type in ['javascript', 'typescript']:
            self._index_js_file(file_path, rel_path)

    def _index_python_file(self, file_path: Path, rel_path: str):
        """ç´¢å¼• Python æ–‡ä»¶ï¼ˆä½¿ç”¨å¢å¼ºæå–å™¨ï¼‰"""
        # Try enhanced extraction first
        if ENHANCED_AST_AVAILABLE:
            try:
                analyzer = EnhancedASTAnalyzer(self.root_path, self.db_path)
                extracted_data = analyzer.analyze_file(file_path)

                if 'error' not in extracted_data:
                    # Use enhanced extraction results
                    self._index_enhanced_data(extracted_data, rel_path)
                    return
            except Exception as e:
                print(f"   âš  Enhanced extraction failed for {rel_path}: {e}, falling back to basic")

        # Fallback to basic extraction
        self._index_python_file_basic(file_path, rel_path)

    def _index_enhanced_data(self, extracted_data: Dict, rel_path: str):
        """ç´¢å¼•å¢å¼ºæå–çš„æ•°æ®"""
        # Index file symbol
        file_id = self._add_symbol(
            name=Path(rel_path).name,
            kind='file',
            file_path=rel_path,
            line_number=1,
            end_line_number=extracted_data.get('line_count', 1),
            metadata=json.dumps(extracted_data)
        )

        # Index classes
        for class_data in extracted_data.get('classes', []):
            class_id = self._add_symbol(
                name=class_data['name'],
                kind='class',
                file_path=rel_path,
                line_number=class_data['line_number'],
                end_line_number=class_data['end_line_number'],
                parent_id=file_id,
                metadata=json.dumps(class_data)
            )

            # Index methods
            for method in class_data.get('methods', []):
                self._add_symbol(
                    name=method['name'],
                    kind='function',
                    file_path=rel_path,
                    line_number=method['line_number'],
                    end_line_number=method['end_line_number'],
                    parent_id=class_id,
                    metadata=json.dumps(method)
                )

            # Index nested classes
            for nested_class in class_data.get('nested_classes', []):
                nested_id = self._add_symbol(
                    name=nested_class['name'],
                    kind='class',
                    file_path=rel_path,
                    line_number=nested_class['line_number'],
                    end_line_number=nested_class['end_line_number'],
                    parent_id=class_id,
                    metadata=json.dumps(nested_class)
                )

        # Index top-level functions
        for func_data in extracted_data.get('functions', []):
            self._add_symbol(
                name=func_data['name'],
                kind='function',
                file_path=rel_path,
                line_number=func_data['line_number'],
                end_line_number=func_data['end_line_number'],
                parent_id=file_id,
                metadata=json.dumps(func_data)
            )

    def _index_python_file_basic(self, file_path: Path, rel_path: str):
        """åŸºæœ¬ Python æ–‡ä»¶ç´¢å¼•ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source = f.read()

            tree = ast.parse(source, filename=str(file_path))

            # ç´¢å¼•æ–‡ä»¶çº§ç¬¦å·
            file_id = self._add_symbol(
                name=Path(rel_path).name,
                kind='file',
                file_path=rel_path,
                line_number=1,
                end_line_number=len(source.splitlines())
            )

            # éå† AST
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    # ç±»å®šä¹‰
                    self._add_symbol(
                        name=node.name,
                        kind='class',
                        file_path=rel_path,
                        line_number=node.lineno,
                        end_line_number=getattr(node, 'end_lineno', node.lineno),
                        parent_id=file_id,
                        metadata=json.dumps({
                            'bases': [ast.unparse(base) for base in node.bases]
                        })
                    )

                elif isinstance(node, ast.FunctionDef):
                    # å‡½æ•°å®šä¹‰
                    self._add_symbol(
                        name=node.name,
                        kind='function',
                        file_path=rel_path,
                        line_number=node.lineno,
                        end_line_number=getattr(node, 'end_lineno', node.lineno),
                        parent_id=file_id,
                        metadata=json.dumps({
                            'args': [arg.arg for arg in node.args.args],
                            'returns': ast.unparse(node.returns) if node.returns else None
                        })
                    )

                elif isinstance(node, ast.AsyncFunctionDef):
                    # å¼‚æ­¥å‡½æ•°å®šä¹‰
                    self._add_symbol(
                        name=node.name,
                        kind='function',
                        file_path=rel_path,
                        line_number=node.lineno,
                        end_line_number=getattr(node, 'end_lineno', node.lineno),
                        parent_id=file_id,
                        metadata=json.dumps({
                            'async': True,
                            'args': [arg.arg for arg in node.args.args],
                            'returns': ast.unparse(node.returns) if node.returns else None
                        })
                    )

        except (SyntaxError, UnicodeDecodeError):
            # æ— æ³•è§£æçš„æ–‡ä»¶ï¼Œåªè®°å½•æ–‡ä»¶çº§ç¬¦å·
            self._add_symbol(
                name=Path(rel_path).name,
                kind='file',
                file_path=rel_path,
                line_number=1,
                end_line_number=1
            )

    def _index_js_file(self, file_path: Path, rel_path: str):
        """ç´¢å¼• JavaScript/TypeScript æ–‡ä»¶ï¼ˆåŸºäºæ­£åˆ™ï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.splitlines()

            # ç´¢å¼•æ–‡ä»¶
            file_id = self._add_symbol(
                name=Path(rel_path).name,
                kind='file',
                file_path=rel_path,
                line_number=1,
                end_line_number=len(lines)
            )

            # ç±»å®šä¹‰: class MyClass { ... }
            class_pattern = r'(?:export\s+)?(?:default\s+)?class\s+(\w+)'
            for match in re.finditer(class_pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                self._add_symbol(
                    name=match.group(1),
                    kind='class',
                    file_path=rel_path,
                    line_number=line_num,
                    parent_id=file_id
                )

            # å‡½æ•°å®šä¹‰: function myFunc(...) { ... }
            func_pattern = r'function\s+(\w+)\s*\('
            for match in re.finditer(func_pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                self._add_symbol(
                    name=match.group(1),
                    kind='function',
                    file_path=rel_path,
                    line_number=line_num,
                    parent_id=file_id
                )

            # ç®­å¤´å‡½æ•°: const myFunc = (...) => { ... }
            arrow_pattern = r'(?:const|let|var)\s+(\w+)\s*=\s*(?:\([^)]*\)|\w+)\s*=>'
            for match in re.finditer(arrow_pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                self._add_symbol(
                    name=match.group(1),
                    kind='function',
                    file_path=rel_path,
                    line_number=line_num,
                    parent_id=file_id
                )

        except (UnicodeDecodeError, OSError):
            # æ— æ³•è¯»å–çš„æ–‡ä»¶
            pass

    def _add_symbol(self, name: str, kind: str, file_path: str,
                   line_number: int, end_line_number: int = None,
                   parent_id: int = None, metadata: str = None) -> int:
        """æ·»åŠ ç¬¦å·åˆ°æ•°æ®åº“"""
        cursor = self.conn.cursor()

        try:
            cursor.execute("""
                INSERT INTO symbols
                (name, kind, file_path, line_number, end_line_number, parent_id, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (name, kind, file_path, line_number, end_line_number, parent_id, metadata))

            self.conn.commit()
            return cursor.lastrowid
        except sqlite3.IntegrityError:
            # ç¬¦å·å·²å­˜åœ¨ï¼Œè¿”å›ç°æœ‰ ID
            cursor.execute("""
                SELECT id FROM symbols
                WHERE name = ? AND kind = ? AND file_path = ? AND line_number = ?
            """, (name, kind, file_path, line_number))
            result = cursor.fetchone()
            return result[0] if result else None


def main():
    import sys

    if len(sys.argv) < 2:
        print("Usage: build_symbol_index.py <project-path> [--output db_path]")
        print("\nExamples:")
        print("  build_symbol_index.py /path/to/project")
        print("  build_symbol_index.py /path/to/project --output /path/to/symbols.db")
        print("\næ³¨æ„ï¼š")
        print("  - æ­¤è„šæœ¬ä½¿ç”¨ SQLite æ„å»ºç¬¦å·ç´¢å¼•")
        print("  - Serena MCP é›†æˆæ­£åœ¨å¼€å‘ä¸­")
        print("  - åœ¨ Claude Code ä¸­å¯ä½¿ç”¨ Serena è¿›è¡Œç¬¦å·çº§åˆ†æ")
        sys.exit(1)

    project_path = Path(sys.argv[1])
    if not project_path.exists():
        print(f"Error: Path does not exist: {project_path}")
        sys.exit(1)

    # è§£æè¾“å‡ºè·¯å¾„
    output_path = "symbols.db"
    if len(sys.argv) > 2 and sys.argv[2] == "--output" and len(sys.argv) > 3:
        output_path = sys.argv[3]

    # æ„å»ºç´¢å¼•
    builder = SymbolIndexBuilder(project_path, db_path=output_path)
    db_path = builder.build_index()

    print(f"âœ… Symbol index built successfully: {db_path}")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("SELECT COUNT(*) FROM symbols")
    symbol_count = cursor.fetchone()[0]

    cursor.execute("SELECT kind, COUNT(*) FROM symbols GROUP BY kind")
    kind_stats = cursor.fetchall()

    cursor.execute("SELECT COUNT(*) FROM files")  # Note: 'files' is not a table, fix this
    # Actually, we should query symbols where kind='file'
    cursor.execute("SELECT COUNT(*) FROM symbols WHERE kind='file'")
    file_count = cursor.fetchone()[0]

    conn.close()

    print(f"\nğŸ“Š Statistics:")
    print(f"  Files indexed: {file_count}")
    print(f"  Total symbols: {symbol_count}")
    print(f"  By type:")
    for kind, count in kind_stats:
        print(f"    - {kind}: {count}")


if __name__ == "__main__":
    main()
